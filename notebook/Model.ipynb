{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-24T06:45:04.640093Z",
     "start_time": "2018-08-24T06:45:04.011011Z"
    }
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (pipeline_utils.py, line 86)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/home/ubuntu/miniconda/envs/home_credit/lib/python3.6/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m2963\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-08b84fbb8709>\"\u001b[0;36m, line \u001b[0;32m26\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    import utils, pipeline_utils\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"../scripts/pipeline_utils.py\"\u001b[0;36m, line \u001b[0;32m86\u001b[0m\n\u001b[0;31m    def __init__(self, dtype):\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "# numpy and pandas for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "# sklearn preprocessing for dealing with categorical variables\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "\n",
    "# File system manangement\n",
    "import os\n",
    "\n",
    "# Suppress warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# matplotlib and seaborn for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, clone\n",
    "from sklearn.preprocessing import MinMaxScaler, Imputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sys\n",
    "sys.path.insert(0, '../scripts/')\n",
    "import utils, pipeline_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-24T03:57:56.162583Z",
     "start_time": "2018-08-24T03:57:56.158708Z"
    }
   },
   "outputs": [],
   "source": [
    "application_path = '../data/application_train.csv'\n",
    "application_path_pkl = '../data/application.pkl'\n",
    "bureau_path = '../data/bureau.csv'\n",
    "bureau_path_pkl = '../data/bureau.pkl'\n",
    "bureau_balance_path = '../data/bureau_balance.csv'\n",
    "bureau_balance_path_pkl = '../data/bureau_balance.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-24T03:58:00.991557Z",
     "start_time": "2018-08-24T03:57:56.164928Z"
    }
   },
   "outputs": [],
   "source": [
    "application_data = load_data_csv(application_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-24T03:58:03.691218Z",
     "start_time": "2018-08-24T03:58:00.994114Z"
    }
   },
   "outputs": [],
   "source": [
    "application_data.to_pickle(application_path_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-24T03:58:03.988602Z",
     "start_time": "2018-08-24T03:58:03.693079Z"
    }
   },
   "outputs": [],
   "source": [
    "application_data = pd.read_pickle(application_path_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-24T03:58:09.774339Z",
     "start_time": "2018-08-24T03:58:03.990173Z"
    }
   },
   "outputs": [],
   "source": [
    "bureau_data = load_data_csv(bureau_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-24T03:58:15.638646Z",
     "start_time": "2018-08-24T03:58:09.776625Z"
    }
   },
   "outputs": [],
   "source": [
    "bureau_balance_data = load_data_csv(bureau_balance_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-24T03:58:15.677420Z",
     "start_time": "2018-08-24T03:58:15.640622Z"
    }
   },
   "outputs": [],
   "source": [
    "application_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-24T03:58:15.786415Z",
     "start_time": "2018-08-24T03:58:15.680559Z"
    }
   },
   "outputs": [],
   "source": [
    "application_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target\n",
    "\n",
    "- 1 - Client with payment difficulties: he/she had late payment more than X days on at least one of the first Y installments of the loan in our sample (will have difficulty repaying loan)\n",
    "- 0 - All other cases (will repay loan on time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-24T03:58:15.882094Z",
     "start_time": "2018-08-24T03:58:15.788884Z"
    }
   },
   "outputs": [],
   "source": [
    "application_data.TARGET.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-24T03:58:15.950621Z",
     "start_time": "2018-08-24T03:58:15.884119Z"
    }
   },
   "outputs": [],
   "source": [
    "application_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-24T03:58:18.488099Z",
     "start_time": "2018-08-24T03:58:15.952922Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "application_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature - Target Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-24T03:58:18.613350Z",
     "start_time": "2018-08-24T03:58:18.490029Z"
    }
   },
   "outputs": [],
   "source": [
    "X, y = extract_X_y(application_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train - Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-24T03:58:19.042344Z",
     "start_time": "2018-08-24T03:58:18.615456Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = splitting(X, y, val_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-24T03:58:19.048231Z",
     "start_time": "2018-08-24T03:58:19.044294Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical - Categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-24T03:58:19.255216Z",
     "start_time": "2018-08-24T03:58:19.049958Z"
    }
   },
   "outputs": [],
   "source": [
    "numeric_columns = X_train.select_dtypes(include='number').columns\n",
    "categorical_columns = list(set(X_train.columns) - set(numeric_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-24T03:58:19.259713Z",
     "start_time": "2018-08-24T03:58:19.256989Z"
    }
   },
   "outputs": [],
   "source": [
    "x_cols = list(X_train.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-24T03:58:19.346384Z",
     "start_time": "2018-08-24T03:58:19.262145Z"
    }
   },
   "outputs": [],
   "source": [
    "preprocess_pipeline = make_pipeline(\n",
    "    ColumnSelector(columns=x_cols),\n",
    "    FeatureUnion(transformer_list=[\n",
    "        (\"numeric_features\", make_pipeline(\n",
    "            TypeSelector(np.number),\n",
    "            Imputer(strategy=\"median\"),\n",
    "            StandardScaler()\n",
    "        )),\n",
    "        (\"categorical_features\", make_pipeline(\n",
    "            TypeSelector(\"object\"),\n",
    "            ToDummiesTransformer()\n",
    "        ))\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-24T03:58:19.470084Z",
     "start_time": "2018-08-24T03:58:19.348420Z"
    }
   },
   "outputs": [],
   "source": [
    "classifier_pipeline = make_pipeline(\n",
    "    preprocess_pipeline,\n",
    "    LogisticRegression(random_state=42)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-24T03:59:26.746968Z",
     "start_time": "2018-08-24T03:58:19.471853Z"
    }
   },
   "outputs": [],
   "source": [
    "classifier_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-24T04:00:08.618993Z",
     "start_time": "2018-08-24T04:00:08.611713Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-24T04:01:04.036045Z",
     "start_time": "2018-08-24T04:01:03.571843Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = classifier_pipeline.predict_proba(X_val)[:, 1]\n",
    "roc_auc_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-24T04:52:25.783406Z",
     "start_time": "2018-08-24T04:52:25.092452Z"
    }
   },
   "outputs": [],
   "source": [
    "application_data_test = pd.read_csv('../data/application_test.csv')\n",
    "# y_pred_test = classifier_pipeline.predict_proba(application_data_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_columns = X_train.columns[X_train.dtypes == object].tolist()\n",
    "object_levels = np.union1d(X_train[object_columns].fillna('NAN'), application_data_test[object_columns].fillna('NAN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-24T04:51:44.091051Z",
     "start_time": "2018-08-24T04:51:44.082598Z"
    }
   },
   "outputs": [],
   "source": [
    "application_data_test.shape, X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-23T09:38:29.186952Z",
     "start_time": "2018-08-23T09:38:28.995928Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bureau_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new names for each of these columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-23T11:15:17.660070Z",
     "start_time": "2018-08-23T11:15:17.651433Z"
    }
   },
   "outputs": [],
   "source": [
    "def agg_numeric(df, group_var, df_name):\n",
    "    \"\"\"Aggregates the numeric values in a dataframe. This can\n",
    "    be used to create features for each instance of the grouping variable.\n",
    "    \n",
    "    Parameters\n",
    "    --------\n",
    "        df (dataframe): \n",
    "            the dataframe to calculate the statistics on\n",
    "        group_var (string): \n",
    "            the variable by which to group df\n",
    "        df_name (string): \n",
    "            the variable used to rename the columns\n",
    "        \n",
    "    Return\n",
    "    --------\n",
    "        agg (dataframe): \n",
    "            a dataframe with the statistics aggregated for \n",
    "            all numeric columns. Each instance of the grouping variable will have \n",
    "            the statistics (mean, min, max, sum; currently supported) calculated. \n",
    "            The columns are also renamed to keep track of features created.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Remove id variables other than grouping variable\n",
    "    for col in df:\n",
    "        if col != group_var and 'SK_ID' in col:\n",
    "            df = df.drop(columns = col)\n",
    "            \n",
    "    group_ids = df[group_var]\n",
    "    numeric_df = df.select_dtypes('number')\n",
    "    numeric_df[group_var] = group_ids\n",
    "\n",
    "    # Group by the specified variable and calculate the statistics\n",
    "    agg = numeric_df.groupby(group_var).agg(['count', 'mean', 'max', 'min', 'sum']).reset_index()\n",
    "\n",
    "    # Need to create new column names\n",
    "    columns = [group_var]\n",
    "\n",
    "    # Iterate through the variables names\n",
    "    for var in agg.columns.levels[0]:\n",
    "        # Skip the grouping variable\n",
    "        if var != group_var:\n",
    "            # Iterate through the stat names\n",
    "            for stat in agg.columns.levels[1][:-1]:\n",
    "                # Make a new column name for the variable and stat\n",
    "                columns.append('%s_%s_%s' % (df_name, var, stat))\n",
    "\n",
    "    agg.columns = columns\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-23T09:30:30.381086Z",
     "start_time": "2018-08-23T09:30:30.375390Z"
    }
   },
   "source": [
    "### Function to Handle Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-23T11:15:18.006709Z",
     "start_time": "2018-08-23T11:15:17.663167Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_categorical(df, group_var, df_name):\n",
    "    \"\"\"Computes counts and normalized counts for each observation\n",
    "    of `group_var` of each unique category in every categorical variable\n",
    "    \n",
    "    Parameters\n",
    "    --------\n",
    "    df : dataframe \n",
    "        The dataframe to calculate the value counts for.\n",
    "        \n",
    "    group_var : string\n",
    "        The variable by which to group the dataframe. For each unique\n",
    "        value of this variable, the final dataframe will have one row\n",
    "        \n",
    "    df_name : string\n",
    "        Variable added to the front of column names to keep track of columns\n",
    "\n",
    "    \n",
    "    Return\n",
    "    --------\n",
    "    categorical : dataframe\n",
    "        A dataframe with counts and normalized counts of each unique category in every categorical variable\n",
    "        with one row for every unique value of the `group_var`.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Select the categorical columns\n",
    "    categorical = pd.get_dummies(df.select_dtypes('object'))\n",
    "\n",
    "    # Make sure to put the identifying id on the column\n",
    "    categorical[group_var] = df[group_var]\n",
    "\n",
    "    # Groupby the group var and calculate the sum and mean\n",
    "    categorical = categorical.groupby(group_var).agg(['sum', 'mean'])\n",
    "    \n",
    "    column_names = []\n",
    "    \n",
    "    # Iterate through the columns in level 0\n",
    "    for var in categorical.columns.levels[0]:\n",
    "        # Iterate through the stats in level 1\n",
    "        for stat in ['count', 'count_norm']:\n",
    "            # Make a new column name\n",
    "            column_names.append('%s_%s_%s' % (df_name, var, stat))\n",
    "    \n",
    "    categorical.columns = column_names\n",
    "    \n",
    "    return categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To recap, for the `bureau_balance` dataframe we:\n",
    "\n",
    "1. Calculated numeric stats grouping by each loan\n",
    "2. Made value counts of each categorical variable grouping by loan\n",
    "3. Merged the stats and the value counts on the loans\n",
    "4. Calculated numeric stats for the resulting dataframe grouping by the client id\n",
    "\n",
    "The final resulting dataframe has one row for each client, with statistics calculated for all of their loans with monthly balance information. \n",
    "\n",
    "Some of these variables are a little confusing, so let's try to explain a few:\n",
    "\n",
    "* `client_bureau_balance_MONTHS_BALANCE_mean_mean`: For each loan calculate the mean value of `MONTHS_BALANCE`. Then for each client, calculate the mean of this value for all of their loans. \n",
    "* `client_bureau_balance_STATUS_X_count_norm_sum`: For each loan, calculate the number of occurences of `STATUS` == X divided by the number of total `STATUS` values for the loan. Then, for each client, add up the values for each loan. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting the functions together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counts of Bureau Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-23T11:15:21.888432Z",
     "start_time": "2018-08-23T11:15:18.008438Z"
    }
   },
   "outputs": [],
   "source": [
    "bureau_counts = count_categorical(bureau_data, group_var = 'SK_ID_CURR', df_name = 'bureau')\n",
    "bureau_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregated Stats of Bureau Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-23T11:15:25.151967Z",
     "start_time": "2018-08-23T11:15:21.889918Z"
    }
   },
   "outputs": [],
   "source": [
    "bureau_agg = agg_numeric(bureau_data.drop(columns = ['SK_ID_BUREAU']), group_var = 'SK_ID_CURR', df_name = 'bureau')\n",
    "bureau_agg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value counts of Bureau Balance dataframe by loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-23T11:15:35.810843Z",
     "start_time": "2018-08-23T11:15:25.154147Z"
    }
   },
   "outputs": [],
   "source": [
    "bureau_balance_counts = count_categorical(bureau_balance_data, group_var = 'SK_ID_BUREAU', df_name = 'bureau_balance')\n",
    "bureau_balance_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregated stats of Bureau Balance dataframe by loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-23T11:15:38.062700Z",
     "start_time": "2018-08-23T11:15:35.814185Z"
    }
   },
   "outputs": [],
   "source": [
    "bureau_balance_agg = agg_numeric(bureau_balance_data, group_var = 'SK_ID_BUREAU', df_name = 'bureau_balance')\n",
    "bureau_balance_agg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregated Stats of Bureau Balance by Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-23T11:15:44.568474Z",
     "start_time": "2018-08-23T11:15:38.065453Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dataframe grouped by the loan\n",
    "bureau_by_loan = bureau_balance_agg.merge(bureau_balance_counts, right_index = True, left_on = 'SK_ID_BUREAU', how = 'outer')\n",
    "\n",
    "# Merge to include the SK_ID_CURR\n",
    "bureau_by_loan = bureau_data[['SK_ID_BUREAU', 'SK_ID_CURR']].merge(bureau_by_loan, on = 'SK_ID_BUREAU', how = 'left')\n",
    "\n",
    "# Aggregate the stats for each client\n",
    "bureau_balance_by_client = agg_numeric(bureau_by_loan.drop(columns = ['SK_ID_BUREAU']), group_var = 'SK_ID_CURR', df_name = 'client')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert Computed Features into Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-23T11:15:44.573672Z",
     "start_time": "2018-08-23T11:15:44.570114Z"
    }
   },
   "outputs": [],
   "source": [
    "original_features = list(application_data.columns)\n",
    "train = application_data\n",
    "print('Original Number of Features: ', len(original_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-23T11:15:53.781255Z",
     "start_time": "2018-08-23T11:15:44.575542Z"
    }
   },
   "outputs": [],
   "source": [
    "# Merge with the value counts of bureau\n",
    "train = train.merge(bureau_counts, on = 'SK_ID_CURR', how = 'left')\n",
    "\n",
    "# Merge with the stats of bureau\n",
    "train = train.merge(bureau_agg, on = 'SK_ID_CURR', how = 'left')\n",
    "\n",
    "# Merge with the monthly information grouped by client\n",
    "train = train.merge(bureau_balance_by_client, on = 'SK_ID_CURR', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-23T11:57:42.397099Z",
     "start_time": "2018-08-23T11:57:42.389737Z"
    }
   },
   "outputs": [],
   "source": [
    "columns_to_delete = []\n",
    "columns_to_delete.append(application_data.columns.values[96:116])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-23T12:18:08.504303Z",
     "start_time": "2018-08-23T12:18:08.136955Z"
    }
   },
   "outputs": [],
   "source": [
    "application_data.loc['APARTMENTS_AVG':'EMERGENCYSTATE_MODE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
